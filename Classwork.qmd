---
title: "In-class_Exercise"
number-sections: false
format: 
  html:
    css: full-width.css
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
toc: true
---

# Classwork 1

## Question 1: Basic multiple regression

![](CW_images/CW1_Q1.png)

### (a)

```{r}
df <- read.csv("Datasets/Clementi2025C.csv")

#(a)
M1 <- lm(Price~., 
               data=df)
summary(M1)
```

### (b)

```{r}
#(b)
M2 <- lm(Price~.+I(Story^2), 
               data=df)
summary(M2)
```

### (c)

```{r}
#(c)
BIC(M1)
BIC(M2) # M2 is better as it has a lower BIC.
```

### (d)

```{r}
# (d)
predict(M2, data.frame(Size=68, Story=10,Model = "Model A", LeaseRemain=80))
# Anwer: 477565.5
```

### (e)

```{r}
# (e)
predict(M2, data.frame(Size=75, Story=6, Model = "New Generation", LeaseRemain=60), interval = "prediction", level =0.99)

# Answer:   fit      lwr      upr 
#         419998.9 336316.7 503681.1
```

### (f)

```{r}
# (f) 

# Answer: Story has a positive relationship with the price
```

## Question 2: Basic ridge/lasso CV + Bagging

![](CW_images/CW1_Q2.png)

### (a)

```{r}
library(glmnet)
df <- read.csv("Datasets/Credit2025C.csv")

set.seed(6677)
x <- model.matrix(Balance~., df)[,-1]
y <- df$Balance
grid <- 10^seq(10, -2, length=100)
set.seed(1)
train <- sample(1:nrow(x), 330) 

test <- (-train)  # the rest as testing set
y.test <- y[test]
y.train <- y[train]

# (a)
R1 <- glmnet(x[train,], y[train], alpha=0)
cvrr.out <- cv.glmnet(x[train,], y[train], alpha=0)
bestlam <- cvrr.out$lambda.mi
bestlam

ridge.pred <-predict(R1, s=bestlam, newx=x[test,])  
mean((ridge.pred-y[test])^2)  # obtain the MSE from the test set

# Answer: Best lambda = 40.05347, Test MSE = 15357.77
```

### (b)

```{r}
set.seed(6677)
R2 <- glmnet(x[train,], y[train], alpha=1)
cvvr.out <- glmnet(x[train,], y[train], alpha=1, lambda=grid)
cvrr.out <- cv.glmnet(x[train,], y[train], alpha=1)
bestlam <- cvrr.out$lambda.mi
bestlam

lasso.pred <-predict(R2, s=bestlam, newx=x[test,])  
mean((lasso.pred-y[test])^2)  # obtain the MSE from the test set

# Answer: Best lambda = 1.655014, Test MSE = 11042.16
```

### (c)

```{r}
library(randomForest)
set.seed(6677)
train <- sample(nrow(df), 330)
df_train <- df[train,]
df_test <- df[-train,]

R3 <- randomForest(Balance~.,
                   data=df,
                   subset=train, 
                   mtry=7, importance=TRUE) #using bagging with training data

yhat.bag <- predict(R3, newdata=df_test)
mean((yhat.bag-df_test[,"Balance"])^2)

# Answer: Test MSE: 8598.558
```

### (d)

```{r}
library(randomForest)
set.seed(6677)
train <- sample(nrow(df), 330)
df_train <- df[train,]
df_test <- df[-train,]

R4 <- randomForest(Balance~.,
                   data=df,
                   subset=train, 
                   mtry=3, importance=TRUE) #using bagging with training data

yhat.bag <- predict(R4, newdata=df_test)
mean((yhat.bag-df_test[,"Balance"])^2)

# Answer: Test MSE: 11909.35  
```

### (e)

```{r}
library(randomForest)
set.seed(6677)

final_model <- randomForest(Balance~.,
                   data=df,
                   mtry=7, importance=TRUE) #using bagging with training data
final_model
# Answer: I would choose the bagging model in part (c) as it has the lowest test MSE
```

### (f)

```{r}
df_5obs = df[1:5,]
df_5obs

yhat.bag <- predict(R4, newdata=df_5obs)
yhat.bag

# All predictions overestimates the actual value of the 5 entries
```

# Classwork 2

## Question 1:

![](CW_images/CW2_Q1.png)

### (a)

```{r}
data <- c(8, 7, 5, 6, 6.4, 8.4, 9.2, 6, 7.5, 4.2, 5.6, 6.2, 7.2, 6.3, 7, 8, 3.7, 4.9, 5.2, 6.2)
M <- matrix(data, nrow=5)  # data matrix with dimension 5x4
M

X <- scale(M)  
sX <- svd(X) # do SVD

d <- sX$d
U <- sX$u
V <- sX$v
D <- diag(d)


pcs <- U %*% D
pcs

# Answer: First principal component for each of the 5 observation: -2.34267393, -0.65362068, 1.83002396, 0.06824995, 1.09802070
#         Second principal component for each of the 5 observation: -0.8709509, 1.5237422, 0.1363334, 0.4150659, -1.2041906
```

### (b)

```{r}
# Using pcob
pcob <- prcomp(M, scale=TRUE)  # use R function prcomp, with scaling
                               # Use scaling when the features are very different

pcob$x 
```

## Question 2:

![](CW_images/CW2_Q2.png)

### (a)

```{r}
df <- read.csv("Datasets/Auto2025C.csv")

# Perform PCA on the scaled data
pr.out <- prcomp(df, scale = TRUE)
pr.out$rotation[,1]  # PC1 loadings

# Answer: PC1:    mpg      cylinders   displacement   horsepower    weight      acceleration 
#              0.3989731   -0.4306152   -0.4435314   -0.4341217   -0.4301031    0.2919257
```

### (b)

```{r}
pr.out$rotation[,2]  # The rotation (loading of each variable on the principal components)

# Answer: PC2:    mpg      cylinders  displacement   horsepower     weight    acceleration 
#              0.2448345   -0.1483141   -0.1084971    0.1661584   -0.2860955   -0.8926523 
```

### (c)

```{r}
biplot(pr.out, scale = 0, main = "The first two Principal Components")
```

### (d)

```{r}
# Answer: Loading value for variable, cylinders on PC1 is -0.4306152
#         Loading value for variable, cylinders on PC2 is -0.1483141
```

### (e)

```{r}
# Cylinders and displacement are highly correlated as they are going in the same direction
```

### (f)

```{r}
# The 27th observation has an approximate first principal component score of -3.8 and an approximate second principal component score of -0.8
```

### (g)

```{r, eval = FALSE}
plot(pve, xlab = "Principal Component", ylab = "Proportion of Variance Explained", ylim = c(0, 1), type = "b")
```

### (h)

```{r}
# Calculate and print the proportion of variance explained by each principal component
pr.var <- pr.out$sdev^2
pve <- pr.var/sum(pr.var)

Information_loss = sum(pve[3:length(pve)])
Information_loss

# Answer: 0.08051712
```

# Classwork 3

## Question 1

![](CW_images/CW3_Q1.png)

### (a)

```{r}
A = c((0+1+2)/3,(0+4+2)/3, (1+3+6)/3)
A

B=c((1-2+0)/3,(2+4+2)/3, (5+8+1)/3)
B

C= c((-1-5-1)/3,(0+3-3)/3, (2+4+4)/3)
C

```

## Question 2

![](CW_images/CW3_Q2.png)

### (a)

```{r}

```

# Classwork 4

## Question 1

![](CW_images/CW4_Q1.png)

### (a)

```{r}
df <- read.csv("Datasets/University2025c.csv")

set.seed(6688)
train <- sample(1:nrow(df), 400)
test <- -train

y <- df[, "Apps"]

lm1 =lm(Apps~., 
        data=df,
        subset=train)
mse1 <- mean((y-predict(lm1, df))[test]^2)
mse1

# Answer: MSE 954154.9
```

## (b)

# Classwork 5

## Question 1

![](CW_images/CW5_Q1.png)

# Classwork 6

## Question 1

![](CW_images/CW6_Q1.png) \### (a)
