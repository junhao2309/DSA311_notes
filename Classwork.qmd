---
title: "In-class_Exercise"
number-sections: false
format: 
  html:
    css: full-width.css
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
toc: true
---

# Classwork 1

## Question 1: Basic multiple regression

![](CW_images/CW1_Q1.png)

### (a)

```{r}
df <- read.csv("Datasets/Clementi2025C.csv", stringsAsFactors = TRUE)

#(a)
M1 <- lm(Price~., 
               data=df)
summary(M1)
```

### (b)

```{r}
#(b)
M2 <- lm(Price~.+I(Story^2), 
               data=df)
summary(M2)
```

### (c)

```{r}
#(c)
BIC(M1)
BIC(M2) # M2 is better as it has a lower BIC.
```

### (d)

```{r}
# (d)
predict(M2, data.frame(Size=68, Story=10,Model = "Model A", LeaseRemain=80))
# Anwer: 477565.5
```

### (e)

```{r}
# (e)
predict(M2, data.frame(Size=75, Story=6, Model = "New Generation", LeaseRemain=60), interval = "prediction", level =0.99)

# Answer:   fit      lwr      upr 
#         419998.9 336316.7 503681.1
```

### (f)

Answer: Since the coefficient estimate of Story and Story^2 are 4737 and -59.9, respectively, the higher Story implies higher price, all else being equal.  But the price increases in the decreasing rate as the quadratic term coefficient is negative.  (Note that the turning point of the curve is at Story equal to 39 which is higher than the maximum of the variable in the data set.) 


## Question 2: Basic ridge/lasso CV + Bagging

![](CW_images/CW1_Q2.png)

```{r}
credit <- read.csv("Datasets/Credit2025C.csv", stringsAsFactors = TRUE)

library(glmnet)
set.seed(6677)

## Train test split
train <- sample(1:nrow(credit), 330)
test <- -train
credit.train <- credit[train,]
credit.test <- credit[test,]

train.x <- model.matrix(Balance~., data=credit.train)[,-1]
train.y <- credit.train$Balance
test.x <- model.matrix(Balance~., data=credit.test)[,-1]
test.y <- credit.test$Balance

# (a)
# ridge regression
ridge.mod <- cv.glmnet(train.x, train.y, alpha=0)
lambda.rr <- ridge.mod$lambda.min
lambda.rr
ridge.pred <- predict(ridge.mod, newx=test.x, s=lambda.rr)
# ridge regression test MSE
mse.rr <- mean((test.y-ridge.pred)^2)
mse.rr

# (b)
lasso.mod <- cv.glmnet(train.x, train.y, alpha=1)
lambda.lasso <- lasso.mod$lambda.min
lambda.lasso
lasso.pred <- predict(lasso.mod, newx=test.x, s=lambda.lasso)

mse.lasso <- mean((test.y-lasso.pred)^2)
mse.lasso

# (c)
library(randomForest)
bag.credit <- randomForest(Balance~.,
 data=credit,
 subset=train, mtry=7) #using bagging
bag.credit
yhat.bag <- predict(bag.credit, newdata=credit.test)
#MSE for bagging
mse.bag <- mean((yhat.bag- credit.test$Balance)^2)
mse.bag

# (d)
#using random forest
rf.credit <- randomForest(Balance~.,
 data=credit,
 subset=train, mtry=3) #using random forest
rf.credit
yhat.rf <- predict(rf.credit, newdata=credit.test)
#MSE for random forest
mse.rf <- mean((yhat.rf- credit.test$Balance)^2)
mse.rf

# (e)
# use all data to construct the model with LASSO approach
x <- model.matrix(Balance~., data=credit)[,-1]
y <- credit$Balance

lasso.all <- glmnet(x, y, alpha=1)
lasso.coef <- predict(lasso.all, type="coefficients", s=lambda.lasso)[1:8,]
lasso.coef[lasso.coef !=0]
yhat <- predict(lasso.all, s=lambda.lasso, newx=x)[1:5]
error <- yhat-y[1:5]
y[1:5]
yhat
error
```

Answer:

(a) MSE1=13141.49; lambda=39.06409
(b) MSE2=7071.47; lambda= 0.7668
(c) MSE3=8811.42
(d) MSE4=11961.33
(e) Lasso model is the recommended model as it has smallest MSE of 8811.42

(Intercept): -512.0792119

Income: -7.8368385

Limit: 0.1265155

Rating: 2.0966366

OwnYes: -5.1476985

StudentYes: 418.8716851

MarriedYes: -6.5196042

RegionSouth: 7.4614610
          

(f) The predicted values of the first five observations are 422, 940, 650, 962 and 419 respectively. The model under-estimates the fourth observation and over-estimates the rest.

# Classwork 2

## Question 1:

![](CW_images/CW2_Q1.png)

### (a)

```{r}
data <- c(8, 7, 5, 6, 6.4, 8.4, 9.2, 6, 7.5, 4.2, 5.6, 6.2, 7.2, 6.3, 7, 8, 3.7, 4.9, 5.2, 6.2)
M <- matrix(data, nrow=5)  # data matrix with dimension 5x4
M

X <- scale(M)  
sX <- svd(X) # do SVD

# Loading score of principal component
V <- sX$v
round(V,4)

# Principal component scores
pcss <- X%*%V
pcss

# Proportion of variance explained
totalsum <-sum(pcss^2)
pc1sum <-sum(pcss[,1]^2)
pc2sum <-sum(pcss[,2]^2)
propvar1 <-pc1sum/totalsum
propvar2 <-pc2sum/totalsum
propvar1
propvar2


# (b)

pres <-prcomp(M, scale=TRUE)
summary(pres)

# Gives you the loading score ofeach principal component
pres$rotation

# Gives you the principal component score for each observation
pres$x

```

Answer: 

(a)

-   The loadings of the first principal component are -0.5742, -0.4595, 0.6085, and -0.2981. The loadings of the second principal component are -0.1583, 0.5929, -0.0861, and -0.7849.

-   The proportion of variance explained by the first principal component is 65.47%. The proportion of variance explained by the second principal component is 29.51%.

-   The first and second principal component scores for the first observation are -2.342 and -0.871, respectively.

-   The first and second principal component scores for the second observation are -654 and 1.524, respectively.

-   The first and second principal component scores for the third observation are 1.830 and 0.136, respectively.

-   The first and second principal component scores for the fourth observation are 0.068and 0.415, respectively.

-   The first and second principal component scores for the fifth observation are 1.098and -1.204, respectively

(b) Gives the same score as seen on the output.

## Question 2:

![](CW_images/CW2_Q2.png)

### (a)

```{r}
df <- read.csv("Datasets/Auto2025C.csv")

# (a)
# Perform PCA on the scaled data
pr.out <- prcomp(df, scale = TRUE)
pr.out$rotation[,1]  # PC1 loadings


# (b)
pr.out$rotation[,2]  # The rotation (loading of each variable on the principal components)

# (c)
biplot(pr.out, scale = 0, main = "The first two Principal Components")

# (g)
# Proportions of variation explained
pr.var <-pr.out$sdev^2
pve <-pr.var/sum(pr.var)
pve 
par(mfrow=c(1,2))
plot(pve, xlab="Principal Component", ylab="Proportion of Variance Explained",ylim=c(0,1), type="b")
plot(cumsum(pve), xlab="Cumulative Principal Component",ylab="Proportion of Variance Explained",ylim=c(0,1), type="b" )

# (h)
Information_loss = 1- sum(pve[1:2])
Information_loss
```

Answer:

(a) PC1: The loadings are 0.3989731, -0.4306152, -0.4435314, -0.4341217, -0.4301031, 0.2919257

(b) PC2: The loadings are 0.2448345, -0.1483141, -0.1084971,0.1661584, -0.2860955 and -0.8926523

(c) Refer to output

(d) Loading value for variable, cylinders on PC1 is -0.4306152
Loading value for variable, cylinders on PC2 is -0.1483141

(e) Cylinders and displacement are highly correlated as they are going in the same direction and are close to each other.

(f) The 27th observation has an approximate first principal component score of -3.646 and an approximate second principal component score of -0.642

(g) The proportions of variance explained by the six principal components are 0.79804436 0.12143852 0.04307789 0.02086284,0.01052940 and 0.00604700.

(h) 8.05% of information is lost

# Classwork 3

## Question 1

![](CW_images/CW3_Q1.png)

### (a)

```{r}
A = c((0+1+2)/3,(0+4+2)/3, (1+3+6)/3)
A

B=c((1-2+0)/3,(2+4+2)/3, (5+8+1)/3)
B

C= c((-1-5-1)/3,(0+3-3)/3, (2+4+4)/3)
C

```

## Question 2

![](CW_images/CW3_Q2.png)

### (a)

```{r}

```

# Classwork 4

## Question 1

![](CW_images/CW4_Q1.png)

### (a)

```{r}
df <- read.csv("Datasets/University2025c.csv")

set.seed(6688)
train <- sample(1:nrow(df), 400)
test <- -train

y <- df[, "Apps"]

lm1 =lm(Apps~., 
        data=df,
        subset=train)
mse1 <- mean((y-predict(lm1, df))[test]^2)
mse1

# Answer: MSE 954154.9
```

## (b)

# Classwork 5

## Question 1

![](CW_images/CW5_Q1.png)

# Classwork 6

## Question 1

![](CW_images/CW6_Q1.png) \### (a)
